```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
```

# 데이터셋 불러오기


```python
df = pd.read_csv("./insurance.csv")
```


```python
df 
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>sex</th>
      <th>bmi</th>
      <th>children</th>
      <th>smoker</th>
      <th>charges</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>19</td>
      <td>0</td>
      <td>27.900</td>
      <td>0</td>
      <td>1</td>
      <td>16884.92400</td>
    </tr>
    <tr>
      <th>1</th>
      <td>18</td>
      <td>1</td>
      <td>33.770</td>
      <td>1</td>
      <td>0</td>
      <td>1725.55230</td>
    </tr>
    <tr>
      <th>2</th>
      <td>28</td>
      <td>1</td>
      <td>33.000</td>
      <td>3</td>
      <td>0</td>
      <td>4449.46200</td>
    </tr>
    <tr>
      <th>3</th>
      <td>33</td>
      <td>1</td>
      <td>22.705</td>
      <td>0</td>
      <td>0</td>
      <td>21984.47061</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32</td>
      <td>1</td>
      <td>28.880</td>
      <td>0</td>
      <td>0</td>
      <td>3866.85520</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1333</th>
      <td>50</td>
      <td>1</td>
      <td>30.970</td>
      <td>3</td>
      <td>0</td>
      <td>10600.54830</td>
    </tr>
    <tr>
      <th>1334</th>
      <td>18</td>
      <td>0</td>
      <td>31.920</td>
      <td>0</td>
      <td>0</td>
      <td>2205.98080</td>
    </tr>
    <tr>
      <th>1335</th>
      <td>18</td>
      <td>0</td>
      <td>36.850</td>
      <td>0</td>
      <td>0</td>
      <td>1629.83350</td>
    </tr>
    <tr>
      <th>1336</th>
      <td>21</td>
      <td>0</td>
      <td>25.800</td>
      <td>0</td>
      <td>0</td>
      <td>2007.94500</td>
    </tr>
    <tr>
      <th>1337</th>
      <td>61</td>
      <td>0</td>
      <td>29.070</td>
      <td>0</td>
      <td>1</td>
      <td>29141.36030</td>
    </tr>
  </tbody>
</table>
<p>1338 rows × 6 columns</p>
</div>




```python
# ( 성별 ; 0은 남자, 1은 여자 )
```


```python
X_data = df.drop(["charges"], axis=1).to_numpy()
Y_data = df["charges"].to_numpy()
```


```python
X_data.shape
```




    (1338, 5)




```python
Y_data.shape
```




    (1338,)




```python
X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=100, shuffle=True)
```


```python
X_train.shape
```




    (1070, 5)




```python
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
# 선형회귀 모델 훈련
lr.fit(X_train, Y_train)
# 예측
pred = lr.predict(X_test)
```


```python
print("기울기", lr.coef_)
print("절편", lr.intercept_)
```

    기울기 [2.64799803e+02 1.73446608e+01 2.97514806e+02 4.69339602e+02
     2.34692802e+04]
    절편 -11576.999976112378
    


```python
print(lr.score(X_train, Y_train))
print(lr.score(X_test, Y_test))
```

    0.7368220127747351
    0.7938983522335603
    


```python
from sklearn.preprocessing import  PolynomialFeatures
ss = PolynomialFeatures(degree=5, include_bias=False)
train_scaled = ss.fit_transform(X_train)
test_scaled = ss.fit_transform(X_test)
```


```python
from sklearn.linear_model import Lasso
lr = Lasso(alpha=10, max_iter=1000)
lr.fit(train_scaled, Y_train)
```
    






```python
print(lr.score(train_scaled, Y_train))
print(lr.score(test_scaled, Y_test))
```

    0.8454782082162202
    0.8598736434044767
    

# 예측 모델 평가하기


```python
# 테이블로 출력하기

comparison = pd.DataFrame(
             {'actual': Y_test,
              'pred': pred})
comparison
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>actual</th>
      <th>pred</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1826.84300</td>
      <td>4765.249466</td>
    </tr>
    <tr>
      <th>1</th>
      <td>20177.67113</td>
      <td>4957.730865</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7421.19455</td>
      <td>8298.988153</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1877.92940</td>
      <td>3078.811868</td>
    </tr>
    <tr>
      <th>4</th>
      <td>15518.18025</td>
      <td>24165.956542</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>263</th>
      <td>1984.45330</td>
      <td>5776.764928</td>
    </tr>
    <tr>
      <th>264</th>
      <td>14283.45940</td>
      <td>23102.847340</td>
    </tr>
    <tr>
      <th>265</th>
      <td>14043.47670</td>
      <td>14280.732585</td>
    </tr>
    <tr>
      <th>266</th>
      <td>8825.08600</td>
      <td>10527.417291</td>
    </tr>
    <tr>
      <th>267</th>
      <td>12124.99240</td>
      <td>11638.260006</td>
    </tr>
  </tbody>
</table>
<p>268 rows × 2 columns</p>
</div>



# 그래프로 출력하기


```python
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 10))
sns.scatterplot(x = "actual", y = "pred", data = comparison)
```




<AxesSubplot:xlabel='actual', ylabel='pred'>


![output_19_1](https://user-images.githubusercontent.com/119285127/204791686-f253ce8f-1944-4bd8-b676-372dcb6fca62.png)


    



```python
from sklearn.metrics import mean_squared_error
mean_squared_error(Y_test, pred) ** 0.5    # RMSE 계산 실행
```




    5684.927776334485




```python
mean_squared_error(Y_test, pred, squared=False)
```




    5684.927776334485




```python
lr.score(train_scaled, Y_train)
```




    0.8454782082162202




```python
print("기울기", lr.coef_)
print("절편", lr.intercept_)
```

    기울기 [-4.89599784e+01 -0.00000000e+00 -4.06964640e+02  3.50733541e+02
      0.00000000e+00  4.70618254e+00  8.31626500e+00 -2.61955823e+00
      1.65298687e+01  4.13778670e+02  0.00000000e+00  2.20934261e+01
      0.00000000e+00 -0.00000000e+00  6.88656663e+00  2.43516111e+01
      2.06993068e+02  3.87957514e+02  0.00000000e+00  0.00000000e+00
      2.13078610e-02 -4.28827187e-01  1.09916129e-02 -1.45830721e+00
     -2.53003686e+00  1.20568238e-01  1.55770804e+00  2.99997659e+01
     -1.55216247e+01  4.64160305e-04 -7.88175131e-01  4.94610242e+00
     -1.13737746e+01  6.02952299e+01 -1.64698079e+02  0.00000000e+00
     -6.96456358e+01  0.00000000e+00 -0.00000000e+00  1.22927858e+00
     -6.02214667e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00
     -0.00000000e+00  6.44549371e-02  1.47229854e+00  1.10188433e+01
      1.23263943e+01 -2.33736033e+01 -1.66449458e+02 -1.50198084e+02
      0.00000000e+00  0.00000000e+00  0.00000000e+00 -7.22147577e-06
     -2.54008460e-02  9.15386776e-04  8.24546233e-03 -3.28658647e-02
      9.27439516e-02  4.79014241e-02  7.36611775e-01  1.85667377e+00
     -1.52534944e-03 -1.18915420e-03 -2.43222928e-02 -3.42513905e-01
     -2.72298800e-01 -1.61295487e+00 -1.02173927e+02  5.60276042e-01
      3.75467445e+01 -4.86211497e+01 -5.02529521e-02 -8.05002369e-01
      4.15022305e+00  9.36546762e+00 -1.01279702e+02 -0.00000000e+00
      1.07641547e-03  2.07755337e-02  1.70930310e-01 -1.44050399e-01
     -1.03835132e+00 -2.49877916e-01 -1.02372511e+00  2.71870400e+01
      1.24771710e+01 -1.41215791e+02  0.00000000e+00 -4.95850930e+01
      0.00000000e+00 -0.00000000e+00  4.10566808e-02 -2.06793094e+01
     -1.35057294e+01  0.00000000e+00 -0.00000000e+00 -0.00000000e+00
      6.76978275e-03  4.51501702e-02  5.28733453e+00  3.13593470e+00
     -9.11214604e+00 -1.87315929e+02 -8.44944837e-01  0.00000000e+00
     -0.00000000e+00 -0.00000000e+00 -1.50460004e-03  2.31719208e-02
      3.61994132e-02  2.11264289e-01 -1.01814598e+00  8.13745285e+00
     -8.50859944e-01  1.61993876e+01 -1.27804825e+01 -1.83267313e+02
     -9.93451792e+00 -6.05476851e+01  0.00000000e+00  0.00000000e+00
      0.00000000e+00 -1.13588983e-05 -2.94161525e-04  1.44098253e-05
      2.11902658e-04  1.43865811e-03  2.47299365e-03  9.92582382e-04
     -3.79873513e-03 -8.71762987e-02 -2.25155492e-05  4.64615171e-04
      1.79256818e-04 -4.22983938e-03  2.36547147e-02 -4.75598891e-02
      1.24489588e+00  4.55141248e-02 -4.03067307e-02  2.73677900e+00
     -1.22883818e-03 -3.28533775e-02 -6.83664874e-02  1.75975794e-01
      1.16960302e+00  2.28542593e+00 -1.16536007e-05  2.55477277e-04
     -3.08114530e-03  1.10366672e-03 -1.59147010e-02  3.65702321e-02
      9.23619102e-02 -5.32316733e-01 -5.63337613e-01 -1.71048509e-01
     -2.77301292e+01  6.77635018e-01 -1.48618584e+01 -1.82695481e+01
     -9.87541370e-03 -1.66431841e+00  4.04149653e+00  7.25007447e+00
     -7.16440154e+01 -0.00000000e+00 -1.85579655e-03  1.06010836e-02
     -2.76551237e-01  4.23830656e-01  2.68009311e+00  8.50266693e+00
     -8.51190247e+00  1.84155659e+01 -9.41406541e+01  0.00000000e+00
      4.21435225e-05 -3.85160429e-04 -4.20609829e-03 -3.28712027e-04
     -1.70786963e-02  2.97785140e-01  7.12205944e-02  3.44199271e-01
     -2.02425340e+00 -2.16146871e-01  8.04990653e-01 -5.18360307e+00
      3.32640875e+01  1.62501791e+01 -1.25759020e+02  0.00000000e+00
      3.48487832e+01  0.00000000e+00 -0.00000000e+00  2.30206744e+00
     -3.72912832e+01 -3.40058239e+01  0.00000000e+00 -0.00000000e+00
     -0.00000000e+00  2.37151095e-02 -1.27807341e-01  4.73949175e+00
      8.40692869e-01  0.00000000e+00 -1.87085280e+02 -8.03030173e-01
      0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -7.57521028e-04
      5.34237986e-02 -2.62070964e-01  6.63518906e-02  2.69762250e+00
      9.97861970e+00 -3.73800141e+00 -4.79077838e+01  5.52984816e+01
     -1.10802381e+02  3.45129088e+01  2.39420116e+02 -0.00000000e+00
     -0.00000000e+00 -0.00000000e+00 -1.68016791e-05 -1.57902684e-03
     -1.39353435e-02 -8.84010617e-03  4.85823889e-03  5.71052310e-01
      1.32188786e-02 -3.36151883e-01  3.94518181e-01  6.52701696e+00
      9.50534280e-02  4.73598237e+00  9.22813414e-01 -5.62711469e+00
     -2.14200305e+02 -1.30938768e+00 -6.13041006e+01 -3.14891764e+01
      0.00000000e+00  0.00000000e+00  0.00000000e+00]
    절편 8612.621256439625
    
